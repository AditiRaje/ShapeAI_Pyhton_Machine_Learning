{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**We generally start our code by importing the libraries which we will use throughout the programme**"
      ],
      "metadata": {
        "id": "6IgQM3Njqp1y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "saoU0WDHW7C8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now we will load the data that we will be using to train our model.**\n",
        "\n",
        "**Here we are using boston house pricing dataset which is availalble in the sklearn library itself. **"
      ],
      "metadata": {
        "id": "miO4esstXJ3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_boston\n",
        "df = load_boston()"
      ],
      "metadata": {
        "id": "72xDzYjZXK43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.keys() # Returns all the keys of dataset dictionary"
      ],
      "metadata": {
        "id": "XOzZG5hyH52i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.DESCR) # Info about the dataset"
      ],
      "metadata": {
        "id": "-Ie6_w0ZIbTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We convert our dataset into the pandas dataframe, so that  it is easier to analyse the data**"
      ],
      "metadata": {
        "id": "UEr9bsw8tMzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "boston = pd.DataFrame(df.data,columns=df.feature_names)\n",
        "boston.head()"
      ],
      "metadata": {
        "id": "XJwe42v0KNXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding a new column of target values to the dataframe **"
      ],
      "metadata": {
        "id": "MvGKM2OMs7aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "boston[\"MEDV\"] = df.target\n",
        "boston.head()"
      ],
      "metadata": {
        "id": "EPSEh4PGMV6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check if the dataset contains any null value or not.**"
      ],
      "metadata": {
        "id": "IV0Ng3rZuekc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "boston.isnull()"
      ],
      "metadata": {
        "id": "RIJIlsa9NG5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boston.isnull().sum()"
      ],
      "metadata": {
        "id": "gpgnK7HJNjxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We never train the model on all the data we have, we always make sure to atleast have test dataset ,  which is different from the training dataset.**"
      ],
      "metadata": {
        "id": "yJk9ySnau563"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = boston.drop(\"MEDV\",axis=1)\n",
        "Y = boston[\"MEDV\"]\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15 , random_state=5)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_train.shape)\n",
        "print(Y_test.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "L9Gufyr2N7ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "gWdCNyzzZpgS"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting model on the training dataset\n",
        "\n",
        "lin_model = LinearRegression()\n",
        "\n",
        "lin_model.fit( X_train, Y_train)"
      ],
      "metadata": {
        "id": "VOm76Sn3ly5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_predict = lin_model.predict(X_train)\n",
        "rmse = (np.sqrt(mean_squared_error(Y_train , y_train_predict)))\n",
        "\n",
        "print(\"The model performance for training set\")\n",
        "print(\"RMSE is {}\".format(rmse))\n",
        "print(\"\\n\")\n",
        "\n",
        "#On testing set\n",
        "\n",
        "y_test_predict = lin_model.predict(X_test)\n",
        "rmse = (np.sqrt(mean_squared_error(Y_test , y_test_predict)))\n",
        "\n",
        "print(\"The model performance for testing set\")\n",
        "print(\" RMSE is {}\".format(rmse))"
      ],
      "metadata": {
        "id": "dpPIBnkUmXoT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}